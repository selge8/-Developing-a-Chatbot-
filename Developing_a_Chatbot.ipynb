{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTDF2hmvbDMZ",
        "outputId": "1074b720-6090-4b08-fe3d-df4345032232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q gradio python-dotenv google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkUGJuN8n5hw"
      },
      "outputs": [],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-93aNvv9aqIV",
        "outputId": "8fe9ca61-63a1-4bcc-fb92-fefeda5867a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up Database Chatbot Assistant for Google Colab...\n",
            "Database already exists at ./database/Northwind.db\n",
            "Starting Database Chatbot Assistant...\n",
            "Terminal will display JSON responses for monitoring\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://05a3f0dd3112090668.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://05a3f0dd3112090668.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> USER QUERY: delete employees table\n",
            "\n",
            "=== JSON RESPONSE FROM GEMINI ===\n",
            "{\"execution_status\": \"error\", \"query_understanding\": \"The user requested to delete the employees table.\", \"sql_query\": \"\", \"error_message\": \"I am not allowed to delete or modify the database schema.\"}\n",
            "===============================\n",
            "\n",
            "\n",
            "=== ERROR RESPONSE ===\n",
            "{\n",
            "  \"response_type\": \"error\",\n",
            "  \"message\": \"I couldn't generate a SQL query for your question. Could you please rephrase it?\"\n",
            "}\n",
            "=====================\n",
            "\n",
            "\n",
            ">>> USER QUERY: list all categories\n",
            "\n",
            "=== JSON RESPONSE FROM GEMINI ===\n",
            "{\"execution_status\": \"success\", \"query_understanding\": \"Retrieve all categories from the Categories table.\", \"sql_query\": \"SELECT * FROM Categories;\", \"error_message\": \"\"}\n",
            "===============================\n",
            "\n",
            "\n",
            "=== SQL EXECUTION RESULTS ===\n",
            "{\n",
            "  \"status\": \"success\",\n",
            "  \"sql_query\": \"SELECT * FROM Categories;\",\n",
            "  \"row_count\": 8,\n",
            "  \"sample\": {\n",
            "    \"CategoryID\": 1,\n",
            "    \"CategoryName\": \"Beverages\",\n",
            "    \"Description\": \"Soft drinks, coffees, teas, beers, and ales\"\n",
            "  }\n",
            "}\n",
            "===========================\n",
            "\n",
            "\n",
            "=== FINAL RESPONSE ===\n",
            "{\n",
            "  \"response_type\": \"query_result\",\n",
            "  \"understanding\": \"Retrieve all categories from the Categories table.\",\n",
            "  \"query\": \"SELECT * FROM Categories;\",\n",
            "  \"result\": {\n",
            "    \"status\": \"success\",\n",
            "    \"sql_query\": \"SELECT * FROM Categories;\",\n",
            "    \"columns\": [\n",
            "      \"CategoryID\",\n",
            "      \"CategoryName\",\n",
            "      \"Description\"\n",
            "    ],\n",
            "    \"rows\": [\n",
            "      {\n",
            "        \"CategoryID\": 1,\n",
            "        \"CategoryName\": \"Beverages\",\n",
            "        \"Description\": \"Soft drinks, coffees, teas, beers, and ales\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 2,\n",
            "        \"CategoryName\": \"Condiments\",\n",
            "        \"Description\": \"Sweet and savory sauces, relishes, spreads, and seasonings\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 3,\n",
            "        \"CategoryName\": \"Confections\",\n",
            "        \"Description\": \"Desserts, candies, and sweet breads\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 4,\n",
            "        \"CategoryName\": \"Dairy Products\",\n",
            "        \"Description\": \"Cheeses\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 5,\n",
            "        \"CategoryName\": \"Grains/Cereals\",\n",
            "        \"Description\": \"Breads, crackers, pasta, and cereal\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 6,\n",
            "        \"CategoryName\": \"Meat/Poultry\",\n",
            "        \"Description\": \"Prepared meats\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 7,\n",
            "        \"CategoryName\": \"Produce\",\n",
            "        \"Description\": \"Dried fruit and bean curd\"\n",
            "      },\n",
            "      {\n",
            "        \"CategoryID\": 8,\n",
            "        \"CategoryName\": \"Seafood\",\n",
            "        \"Description\": \"Seaweed and fish\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "=====================\n",
            "\n",
            "\n",
            ">>> USER QUERY: thanks\n",
            "\n",
            "=== JSON RESPONSE FROM GEMINI ===\n",
            "{\"execution_status\": \"success\", \"query_understanding\": \"This is an acknowledgement and doesn't require a database query.\", \"sql_query\": \"\", \"error_message\": \"\"}\n",
            "===============================\n",
            "\n",
            "\n",
            "=== ERROR RESPONSE ===\n",
            "{\n",
            "  \"response_type\": \"error\",\n",
            "  \"message\": \"I couldn't generate a SQL query for your question. Could you please rephrase it?\"\n",
            "}\n",
            "=====================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import sqlite3\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Function to create or download the database\n",
        "def setup_database():\n",
        "    \"\"\"Downloads or creates the Northwind database file and returns the path\"\"\"\n",
        "    # Define paths\n",
        "    db_dir = \"./database\"\n",
        "    db_path = f\"{db_dir}/Northwind.db\"\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    if not os.path.exists(db_dir):\n",
        "        os.makedirs(db_dir)\n",
        "\n",
        "    # Check if DB already exists\n",
        "    if os.path.exists(db_path):\n",
        "        print(f\"Database already exists at {db_path}\")\n",
        "        return db_path\n",
        "\n",
        "    #Allow user to upload a database file\n",
        "    print(\"Please upload your Northwind.db file\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        # Get the filename of the uploaded file\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        # Move the file to the desired location\n",
        "        with open(db_path, 'wb') as f:\n",
        "            f.write(uploaded[filename])\n",
        "        print(f\"Database uploaded to {db_path}\")\n",
        "        return db_path\n",
        "\n",
        "# Define the response schema for structured output\n",
        "response_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"query_understanding\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Brief explanation of how the system interpreted the user's question\"\n",
        "        },\n",
        "        \"sql_query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The generated SQL query to execute on the database\"\n",
        "        },\n",
        "        \"execution_status\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"success\", \"error\"],\n",
        "            \"description\": \"Status of the query execution\"\n",
        "        },\n",
        "        \"error_message\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Error message if the execution failed\"\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"query_understanding\", \"sql_query\", \"execution_status\"]\n",
        "}\n",
        "\n",
        "# Function to get Gemini response using chat model\n",
        "def get_gemini_chat_response(question, system_prompt):\n",
        "    # Initialize the chat model\n",
        "    model = genai.GenerativeModel(\n",
        "        'gemini-1.5-pro',\n",
        "        generation_config={\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 0.95,\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Start a chat session\n",
        "    chat = model.start_chat(\n",
        "        history=[{\"role\": \"user\", \"parts\": [system_prompt]}]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Send the user query to the chat session\n",
        "        response = chat.send_message(\n",
        "            question,\n",
        "            generation_config={\"response_schema\": response_schema}\n",
        "        )\n",
        "\n",
        "        # Print JSON response to terminal\n",
        "        print(\"\\n=== JSON RESPONSE FROM GEMINI ===\")\n",
        "        print(response.text)\n",
        "        print(\"===============================\\n\")\n",
        "\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        error_response = json.dumps({\n",
        "            \"query_understanding\": \"Error processing query\",\n",
        "            \"sql_query\": \"\",\n",
        "            \"execution_status\": \"error\",\n",
        "            \"error_message\": str(e),\n",
        "            \"explanation\": \"There was an error processing your query. Please try again.\"\n",
        "        })\n",
        "        print(\"\\n=== ERROR RESPONSE ===\")\n",
        "        print(error_response)\n",
        "        print(\"=====================\\n\")\n",
        "        return error_response\n",
        "\n",
        "# Function to execute SQL query\n",
        "def execute_sql_query(sql_query, db_path):\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(sql_query)\n",
        "        rows = cur.fetchall()\n",
        "        column_names = [desc[0] for desc in cur.description]  # Get column names\n",
        "        conn.close()\n",
        "\n",
        "        # Convert query results into JSON structure\n",
        "        results = [dict(zip(column_names, row)) for row in rows]\n",
        "\n",
        "        # Print SQL results to terminal in JSON format\n",
        "        print(\"\\n=== SQL EXECUTION RESULTS ===\")\n",
        "        print(json.dumps({\n",
        "            \"status\": \"success\",\n",
        "            \"sql_query\": sql_query,\n",
        "            \"row_count\": len(rows),\n",
        "            \"sample\": results[0] if results else \"No results\"\n",
        "        }, indent=2))\n",
        "        print(\"===========================\\n\")\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"sql_query\": sql_query,\n",
        "            \"columns\": column_names,\n",
        "            \"rows\": results\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(\"\\n=== SQL ERROR ===\")\n",
        "        print(json.dumps({\n",
        "            \"status\": \"error\",\n",
        "            \"sql_query\": sql_query,\n",
        "            \"error_message\": str(e)\n",
        "        }, indent=2))\n",
        "        print(\"================\\n\")\n",
        "\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"sql_query\": sql_query,\n",
        "            \"error_message\": str(e)\n",
        "        }\n",
        "\n",
        "# Main function to process user query\n",
        "def process_query(question, db_path, history=None):\n",
        "\n",
        "\n",
        "    # Print user query to terminal\n",
        "    print(f\"\\n>>> USER QUERY: {question}\")\n",
        "\n",
        "    # For empty initial messages, return a welcome message\n",
        "    if not question.strip():\n",
        "        return json.dumps({\n",
        "            \"response_type\": \"welcome\",\n",
        "            \"message\": \"Welcome, manager! How can I help you today?\",\n",
        "        }, indent=2)\n",
        "\n",
        "    # Enhanced system prompt with date functions and complex query examples\n",
        "    system_prompt = \"\"\"\n",
        "You are NorthwindAssistant, a database assistant that helps managers query the Northwind database. Your job is to:\n",
        "1. Understand questions in English or Turkish and answer them in the same language\n",
        "2. Convert them to SQL queries that work specifically with SQLite syntax\n",
        "3. Return results in structured JSON format\n",
        "\n",
        "IMPORTANT:\n",
        "- For date calculations, use SQLite date functions like julianday(), date(), strftime()\n",
        "- For date comparisons, ensure proper format conversion\n",
        "- Use proper SQL aggregate functions (AVG, MAX, MIN, COUNT, SUM)\n",
        "- Always check table relationships before joining\n",
        "\n",
        "DATABASE SCHEMA:\n",
        "\n",
        "Categories: CategoryID, CategoryName, Description\n",
        "Customers: CustomerID, CustomerName, ContactName, Address, City, PostalCode, Country\n",
        "Employees: EmployeeID, LastName, FirstName, BirthDate (TEXT format: 'YYYY-MM-DD'), Photo, Notes\n",
        "Shippers: ShipperID, ShipperName, Phone\n",
        "Suppliers: SupplierID, SupplierName, ContactName, Address, City, PostalCode, Country, Phone\n",
        "Products: ProductID, ProductName, SupplierID, CategoryID, Unit, Price\n",
        "Orders: OrderID, CustomerID, EmployeeID, OrderDate (DATETIME format), ShipperID\n",
        "Order Details: OrderDetailID, OrderID, ProductID, Quantity\n",
        "\n",
        "EXAMPLE QUERIES:\n",
        "\n",
        "1. \"What's the average price of all products?\"\n",
        "SQL: SELECT AVG(Price) as AveragePrice FROM Products;\n",
        "\n",
        "2. \"Which employee's birthday is closest to today?\"\n",
        "SQL: SELECT EmployeeID, FirstName, LastName, BirthDate FROM Employees ORDER BY ABS(julianday(strftime('%m-%d', BirthDate)) - julianday(strftime('%m-%d', 'now'))) ASC LIMIT 1;\n",
        "\n",
        "3. \"Show me the total sales by country in 2023\"\n",
        "SQL: SELECT c.Country, SUM(od.Quantity * p.Price) as TotalSales FROM Orders o\n",
        "JOIN Customers c ON o.CustomerID = c.CustomerID\n",
        "JOIN \"Order Details\" od ON o.OrderID = od.OrderID\n",
        "JOIN Products p ON od.ProductID = p.ProductID\n",
        "WHERE strftime('%Y', o.OrderDate) = '2023' GROUP BY c.Country ORDER BY TotalSales DESC;\n",
        "\n",
        "4. \"Who are our top 5 employees by sales?\"\n",
        "SQL: SELECT e.EmployeeID, e.FirstName, e.LastName, SUM(od.Quantity * p.Price) as TotalSales\n",
        "FROM Employees e\n",
        "JOIN Orders o ON e.EmployeeID = o.EmployeeID\n",
        "JOIN \"Order Details\" od ON o.OrderID = od.OrderID\n",
        "JOIN Products p ON od.ProductID = p.ProductID\n",
        "GROUP BY e.EmployeeID ORDER BY TotalSales DESC LIMIT 5;\n",
        "\n",
        "5. \"En çok satış yapılan 3 ülke hangisidir?\" (What are the top 3 countries by sales?)\n",
        "SQL: SELECT c.Country, COUNT(o.OrderID) as OrderCount FROM Orders o JOIN Customers c ON o.CustomerID = c.CustomerID GROUP BY c.Country ORDER BY OrderCount DESC LIMIT 3;\n",
        "\n",
        "For any user question, respond with this JSON structure:\n",
        "{\n",
        "  \"query_understanding\": \"Brief explanation of the user's question\",\n",
        "  \"sql_query\": \"SQL query to execute\",\n",
        "  \"execution_status\": \"success\",\n",
        "  \"error_message\": \"\",\n",
        "  \"explanation\": \"Explanation of the results in user's language\"\n",
        "}\n",
        "\n",
        "If you can't generate a valid SQL query, set execution_status to \"error\" and provide an error_message.\n",
        "\n",
        "Remember to handle SQLite's specific date formats and functions correctly when dealing with date calculations.\n",
        "Don't edit/delete any tables/columns/rows from the database.\n",
        "\"\"\"\n",
        "\n",
        "    # Get the response from Gemini chat\n",
        "    try:\n",
        "        llm_response = get_gemini_chat_response(question, system_prompt)\n",
        "        llm_data = json.loads(llm_response)\n",
        "\n",
        "        # Extract the SQL query\n",
        "        sql_query = llm_data.get(\"sql_query\", \"\")\n",
        "\n",
        "        # If no SQL query or status is error, return the explanation from the LLM\n",
        "        if not sql_query or llm_data.get(\"execution_status\") == \"error\":\n",
        "            error_response = json.dumps({\n",
        "                \"response_type\": \"error\",\n",
        "                \"message\": llm_data.get(\"explanation\", \"I couldn't generate a SQL query for your question. Could you please rephrase it?\")\n",
        "            }, indent=2)\n",
        "            print(\"\\n=== ERROR RESPONSE ===\")\n",
        "            print(error_response)\n",
        "            print(\"=====================\\n\")\n",
        "            return error_response\n",
        "\n",
        "        # Execute the SQL query\n",
        "        result = execute_sql_query(sql_query, db_path)\n",
        "\n",
        "        # Create the combined response\n",
        "        final_response = json.dumps({\n",
        "            \"response_type\": \"query_result\",\n",
        "            \"understanding\": llm_data.get(\"query_understanding\", \"\"),\n",
        "            \"query\": sql_query,\n",
        "            \"result\": result\n",
        "        }, indent=2)\n",
        "\n",
        "        # Print final response to terminal\n",
        "        print(\"\\n=== FINAL RESPONSE ===\")\n",
        "        print(final_response)\n",
        "        print(\"=====================\\n\")\n",
        "\n",
        "        return final_response\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing the request: {str(e)}\"\n",
        "        error_response = json.dumps({\n",
        "            \"response_type\": \"error\",\n",
        "            \"message\": error_msg,\n",
        "            \"raw_response\": llm_response if 'llm_response' in locals() else \"No response generated\"\n",
        "        }, indent=2)\n",
        "        print(\"\\n=== PROCESS ERROR ===\")\n",
        "        print(error_response)\n",
        "        print(\"====================\\n\")\n",
        "        return error_response\n",
        "\n",
        "# Define the respond function outside of the Blocks context\n",
        "def respond(message, chat_history, db_path):\n",
        "    # Process the query\n",
        "    response = process_query(message, db_path)\n",
        "\n",
        "    try:\n",
        "        # Parse the JSON response from the LLM\n",
        "        response_data = json.loads(response)\n",
        "        response_type = response_data.get(\"response_type\", \"\")\n",
        "\n",
        "\n",
        "        # Add user message to history if not empty\n",
        "        if message.strip():\n",
        "            chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        if response_type == \"welcome\" or response_type == \"clarification\":\n",
        "            # Simple welcome or clarification response\n",
        "            bot_message = response_data.get(\"message\", \"\")\n",
        "\n",
        "        elif response_type == \"query_result\":\n",
        "            # We have a successful query result\n",
        "            result = response_data.get(\"result\", {})\n",
        "\n",
        "            if result.get(\"status\") == \"success\":\n",
        "                rows = result.get(\"rows\", [])\n",
        "                columns = result.get(\"columns\", [])\n",
        "\n",
        "                # Start building a user-friendly answer\n",
        "                bot_message = \"\"\n",
        "\n",
        "                # 1) Provide a quick sentence about the result\n",
        "                #    If there's only 1 row & 1 column, we can say \"The X is Y.\"\n",
        "                if len(columns) == 1 and len(rows) == 1:\n",
        "                    col_name = columns[0]\n",
        "                    value = rows[0].get(col_name, \"\")\n",
        "                    bot_message += f\"The **{col_name}** is **{value}**.\\n\\n\"\n",
        "                else:\n",
        "                    # Otherwise, just say we have multiple results\n",
        "                    bot_message += \"Here are your query results:\\n\\n\"\n",
        "\n",
        "                # 2) Show the data in a table\n",
        "                if columns:\n",
        "                    # Table headers\n",
        "                    bot_message += \"| \" + \" | \".join(columns) + \" |\\n\"\n",
        "                    bot_message += \"| \" + \" | \".join([\"---\" for _ in columns]) + \" |\\n\"\n",
        "\n",
        "                    # Table rows (no limit)\n",
        "                for row in rows:\n",
        "                    bot_message += \"| \" + \" | \".join(str(row.get(col, \"\")) for col in columns) + \" |\\n\"\n",
        "\n",
        "\n",
        "                # 3) Finally, add the explanation\n",
        "                explanation = response_data.get(\"explanation\", \"\")\n",
        "                if explanation:\n",
        "                    bot_message += f\"\\n**Explanation**: {explanation}\"\n",
        "\n",
        "            else:\n",
        "                # If the SQL execution failed\n",
        "                bot_message = f\"Error executing query: {result.get('error_message', 'Unknown error')}\"\n",
        "\n",
        "        elif response_type == \"error\":\n",
        "            # LLM couldn't generate a query or something else went wrong\n",
        "            bot_message = response_data.get(\"message\", \"I couldn't process your request properly.\")\n",
        "\n",
        "        else:\n",
        "            # Fallback if we don't recognize the response type\n",
        "            bot_message = \"I couldn't process your request properly.\"\n",
        "\n",
        "        # Add the final bot message to the chat history\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n",
        "\n",
        "        # Return the updated history and clear the user input box\n",
        "        return chat_history, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # If something goes wrong in formatting the response\n",
        "        error_msg = f\"Error processing response: {str(e)}\"\n",
        "        print(\"\\n=== RESPONSE FORMATTING ERROR ===\")\n",
        "        print(json.dumps({\"error\": error_msg}, indent=2))\n",
        "        print(\"===============================\\n\")\n",
        "\n",
        "        # Add to chat history for debugging\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "        return chat_history, \"\"\n",
        "\n",
        "\n",
        "# Function to initialize the chat with a welcome message\n",
        "def init_chat():\n",
        "    chat_history = []\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": \"Welcome, manager! How can I help you today? \"})\n",
        "    return chat_history, \"\"\n",
        "\n",
        "# Create the Gradio interface with database path as a state variable\n",
        "def create_demo(db_path):\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Database Chatbot Assistant\")\n",
        "\n",
        "        chatbot = gr.Chatbot(type=\"messages\")\n",
        "        msg = gr.Textbox(placeholder=\"Ask about the Northwind database...\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "\n",
        "        # Set up event handlers within the Blocks context\n",
        "        # Use a partial application to include the database path\n",
        "        msg.submit(lambda message, history: respond(message, history, db_path), [msg, chatbot], [chatbot, msg])\n",
        "        clear.click(lambda: ([], \"\"), None, [chatbot, msg])\n",
        "\n",
        "        # Initialize the chatbot with a welcome message\n",
        "        demo.load(init_chat, None, [chatbot, msg])\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Main function to set up and run everything\n",
        "def main():\n",
        "    print(\"Setting up Database Chatbot Assistant for Google Colab...\")\n",
        "\n",
        "    # Set up database\n",
        "    db_path = setup_database()\n",
        "\n",
        "    # Create and launch the demo\n",
        "    print(\"Starting Database Chatbot Assistant...\")\n",
        "    print(\"Terminal will display JSON responses for monitoring\")\n",
        "    demo = create_demo(db_path)\n",
        "    demo.launch(debug=True, share=True)  # share=True creates a public link\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}